{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clasificaciones con TRAINER - mBERT - crosslingual.ipynb","provenance":[],"collapsed_sections":["IaLnDfGYiW4e","W0BcGi97iOLp","oIP3b3vfmofI","UWlNtsLFm7Le","lYZavFpEtnqi","M0QVxSGJw36g","wiMpXakcxleJ"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fd475623bcbb4e2db6b1581cc43cc3da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_46eb47f8b9cc4a5ab64d99fbcdeeb37c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cff23d39408e49ca9e3e9452b1513deb","IPY_MODEL_cd2b1c90edae43deae56ad7c5754eee7"]}},"46eb47f8b9cc4a5ab64d99fbcdeeb37c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cff23d39408e49ca9e3e9452b1513deb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_373944b57e284550a89a44ce47f2e2d2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f69c96c8fc494a2ba3a91eabc4e6f5ef"}},"cd2b1c90edae43deae56ad7c5754eee7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d5c3324d17254d82bd43b2f2cb644596","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:11&lt;00:00, 88.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0668d890f1df4e29910eed70e4871330"}},"373944b57e284550a89a44ce47f2e2d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f69c96c8fc494a2ba3a91eabc4e6f5ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5c3324d17254d82bd43b2f2cb644596":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0668d890f1df4e29910eed70e4871330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ab47fa90e954e0fa30cb40bc6f75f15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a83dd71a8d24d09aecf6f68d9d8f0d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a50c8fcaeaf545e3af2956a48cbfc685","IPY_MODEL_65420ce58d03433aadf31dfe5124354a"]}},"8a83dd71a8d24d09aecf6f68d9d8f0d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a50c8fcaeaf545e3af2956a48cbfc685":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8da0298d361544fba0943395c102ceb6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8aad93bc67694698b31317168f40a3bf"}},"65420ce58d03433aadf31dfe5124354a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0a3e25c88e934e028c59d860416d3bbe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:10&lt;00:00, 57.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbe60ce1688942729f7723692a00891e"}},"8da0298d361544fba0943395c102ceb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8aad93bc67694698b31317168f40a3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a3e25c88e934e028c59d860416d3bbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dbe60ce1688942729f7723692a00891e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3120d8017eed44d49f67480b33ff57e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fb01adf14d2e46bfaf0ce3c3952089cf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_29130d2603d24ae5b408b3612b722d92","IPY_MODEL_33f3f5299d5f4bcc968a9bfd10109d3c"]}},"fb01adf14d2e46bfaf0ce3c3952089cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29130d2603d24ae5b408b3612b722d92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4f3f1a9981274dd193d1c26fa70cb4e3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_009c311108a24a24ba2dfd3f46cc7016"}},"33f3f5299d5f4bcc968a9bfd10109d3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83eeee9067c3448a9544cd8b4847aa74","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:10&lt;00:00, 67.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bbb657e6a46a421089f2ec6811c373db"}},"4f3f1a9981274dd193d1c26fa70cb4e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"009c311108a24a24ba2dfd3f46cc7016":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83eeee9067c3448a9544cd8b4847aa74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bbb657e6a46a421089f2ec6811c373db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IaLnDfGYiW4e"},"source":["# Librerias"]},{"cell_type":"code","metadata":{"id":"7UFpAiQTiYjx"},"source":["%%capture \n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f35SHFtzimJ-"},"source":["from sklearn.model_selection import train_test_split\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwHGF_UbJA-G"},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"1822fIjbOM8D","executionInfo":{"status":"ok","timestamp":1613570937033,"user_tz":-60,"elapsed":29290,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"c92c9230-3de5-4aa2-ebf3-0251e6c30020"},"source":["%%capture\n","!pip install wandb\n","import wandb\n","wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["wandb: Paste an API key from your profile and hit enter: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFRKUzUIOPn1","executionInfo":{"status":"ok","timestamp":1613570937034,"user_tz":-60,"elapsed":28810,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"f585a950-6b9c-455a-b9f3-325c85cdf57b"},"source":["wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucialarraona\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"fRn0d1SIhD2w"},"source":["# Carga de datos\n","- incluidas nuevas columnas con concatenacion de review_body y categoria, review_body y titulo\n","- nuevos indices para star rating, de 0-4 en vez de 1-5\n","- numericalizar las categorias de los productos, 31 en total\n","\n","Para TRAIN:\n","  - data ingles EN \n","  - data aleman DE\n","\n","Para VALID Y TEST:\n","  - data en ingles EN\n","  - data en aleman DE\n","  - data en espaÃ±ol ES\n","  - data en francÃ©s FR\n","  - data en japones JA\n","  - data en chino ZH"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hpRSXd3g9e6","executionInfo":{"status":"ok","timestamp":1613571064458,"user_tz":-60,"elapsed":154631,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"debe6145-d07f-4de6-cdcf-4e924e600dde"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TSwvSunMhDUm"},"source":["# Load data\n","import pandas as pd\n","\n","##Â Para TRAIN, en ingles y en aleman\n","\n","path1 = \"/content/drive/MyDrive/TFG/Datasets_procesados_2/train/amazonEN_train.csv\"\n","#path1 = \"drive/MyDrive/TFG_1/Datasets_procesados/train/amazonDE_train.csv\"\n","\n","##Â Para VALID, en ingles, aleman, espaÃ±ol, frances, japones y chino\n","\n","#path2 = \"drive/MyDrive/TFG_1/Datasets_procesados/valid/amazonEN_valid.csv\"\n","path2 = \"/content/drive/MyDrive/TFG/Datasets_procesados_2/valid/amazonDE_valid.csv\"\n","#path2 = \"/content/drive/MyDrive/TFG/Datasets_procesados_2/valid/amazonES_valid.csv\"\n","#path2 = \"content/drive/MyDrive/TFG_1/Datasets_procesados/valid/amazonFR_valid.csv\"\n","#path2 = \"content/drive/MyDrive/TFG_1/Datasets_procesados/valid/amazonJA_valid.csv\"\n","#path2 = \"content/drive/MyDrive/TFG_1/Datasets_procesados/valid/amazonZH_valid.csv\"\n","\n","##Â Para TEST, en ingles, aleman, espaÃ±ol, frances, japones y chino\n","\n","#path3 = \"drive/MyDrive/TFG_1/Datasets_procesados/test/amazonEN_test.csv\"\n","path3 = \"/content/drive/MyDrive/TFG/Datasets_procesados_2/test/amazonDE_test.csv\"\n","#path3 = \"/content/drive/MyDrive/TFG/Datasets_procesados_2/test/amazonES_test.csv\"\n","#path3 = \"drive/MyDrive/TFG_1/Datasets_procesados/test/amazonFR_test.csv\"\n","#path3 = \"drive/MyDrive/TFG_1/Datasets_procesados/test/amazonJA_test.csv\"\n","#path3 = \"drive/MyDrive/TFG_1/Datasets_procesados/test/amazonZH_test.csv\"\n","\n","\n","\n","####### CONVERTIMOS A DATAFRAMES #########\n","\n","df_train = pd.read_csv(path1)\n","df_train = df_train\n","\n","df_valid = pd.read_csv(path2)\n","df_valid = df_valid\n","\n","df_test = pd.read_csv(path3)\n","df_test = df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"6RQEjf46nZdX","executionInfo":{"status":"ok","timestamp":1613571069220,"user_tz":-60,"elapsed":158651,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"1e443388-9414-40c9-ec36-5766eb17a5fe"},"source":["df_train.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review_id</th>\n","      <th>product_id</th>\n","      <th>reviewer_id</th>\n","      <th>star_rating</th>\n","      <th>review_body</th>\n","      <th>review_title</th>\n","      <th>language</th>\n","      <th>product_category</th>\n","      <th>text_title</th>\n","      <th>text_title_cat</th>\n","      <th>text_cat</th>\n","      <th>product_category_cod</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>en_0522546</td>\n","      <td>product_en_0681589</td>\n","      <td>reviewer_en_0687817</td>\n","      <td>2</td>\n","      <td>Not strong enough to run a small 120v vacuum c...</td>\n","      <td>Not strong enough to run a small 120v vacuum c...</td>\n","      <td>en</td>\n","      <td>lawn_and_garden</td>\n","      <td>Not strong enough to run a small 120v vacuum c...</td>\n","      <td>Not strong enough to run a small 120v vacuum c...</td>\n","      <td>Not strong enough to run a small 120v vacuum c...</td>\n","      <td>17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    review_id  ... product_category_cod\n","0  en_0522546  ...                   17\n","\n","[1 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"W0BcGi97iOLp"},"source":["# Carga modelo mBERT\n","- incluye tokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["fd475623bcbb4e2db6b1581cc43cc3da","46eb47f8b9cc4a5ab64d99fbcdeeb37c","cff23d39408e49ca9e3e9452b1513deb","cd2b1c90edae43deae56ad7c5754eee7","373944b57e284550a89a44ce47f2e2d2","f69c96c8fc494a2ba3a91eabc4e6f5ef","d5c3324d17254d82bd43b2f2cb644596","0668d890f1df4e29910eed70e4871330"]},"id":"dc7JoaRnh34h","executionInfo":{"status":"ok","timestamp":1613571070540,"user_tz":-60,"elapsed":159507,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"995f1cf0-749b-42eb-99de-45ead7e120ff"},"source":["PRE_TRAINED_MODEL_NAME = 'bert-base-multilingual-cased'\n","from transformers import BertModel, BertConfig, BertTokenizer\n","from transformers import BertForSequenceClassification\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd475623bcbb4e2db6b1581cc43cc3da","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-2LSsgFij0Xk"},"source":["# mBertForSequenceClassification - RATING\n","- ClasificaciÃ³n Rating a partir de review_body"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKOVvJ95OVGY","executionInfo":{"status":"ok","timestamp":1613571070544,"user_tz":-60,"elapsed":159122,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"db03dda1-2a45-4880-a96d-b0c3fa918cb4"},"source":["%env WANDB_PROJECT = RATING CLASSIFICATION mBERT "],"execution_count":null,"outputs":[{"output_type":"stream","text":["env: WANDB_PROJECT=RATING CLASSIFICATION mBERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K868-ZqRifki"},"source":["RANDOM_SEED=8\n","MAX_LENGTH=512\n","\n","\n","## CLASES DEL CLASIFICADOR \n","\n","class_names = ['0','1','2','3','4'] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCYGgZimjMXy"},"source":["#TOKENIZAMOS LOS DATAFRAMES\n","\n","train_encodings = tokenizer(df_train.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","val_encodings = tokenizer(df_valid.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","test_encodings = tokenizer(df_test.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbZwUznzjbso"},"source":["class GPReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQa18Qyojncq"},"source":["train_labels = df_train.star_rating.values\n","val_labels = df_valid.star_rating.values\n","test_labels = df_test.star_rating.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxFmuoDQjoTf"},"source":["train_data = GPReviewDataset(train_encodings, torch.from_numpy(train_labels))\n","val_data = GPReviewDataset(val_encodings, torch.from_numpy(val_labels))\n","test_data = GPReviewDataset(test_encodings, torch.from_numpy(test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220,"referenced_widgets":["7ab47fa90e954e0fa30cb40bc6f75f15","8a83dd71a8d24d09aecf6f68d9d8f0d1","a50c8fcaeaf545e3af2956a48cbfc685","65420ce58d03433aadf31dfe5124354a","8da0298d361544fba0943395c102ceb6","8aad93bc67694698b31317168f40a3bf","0a3e25c88e934e028c59d860416d3bbe","dbe60ce1688942729f7723692a00891e","3120d8017eed44d49f67480b33ff57e2","fb01adf14d2e46bfaf0ce3c3952089cf","29130d2603d24ae5b408b3612b722d92","33f3f5299d5f4bcc968a9bfd10109d3c","4f3f1a9981274dd193d1c26fa70cb4e3","009c311108a24a24ba2dfd3f46cc7016","83eeee9067c3448a9544cd8b4847aa74","bbb657e6a46a421089f2ec6811c373db"]},"id":"usFdcdYej3rp","executionInfo":{"status":"ok","timestamp":1613571148253,"user_tz":-60,"elapsed":234657,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"0fd2cd86-2848-4c73-bc0f-af9a6ea6b9b0"},"source":["from transformers import BertForSequenceClassification\n","\n","##Â DEFINIMOS EL MODELO \n","\n","model = BertForSequenceClassification.from_pretrained(\n","    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(class_names), # The number of output labels--2 for binary classification.  si pones num_labels=1 hace MSE LOSS\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False ,# Whether the model returns all hidden-states.   \n","    vocab_size=tokenizer.vocab_size)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ab47fa90e954e0fa30cb40bc6f75f15","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3120d8017eed44d49f67480b33ff57e2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descriâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"exEBcFJzkPGr"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nLl7UJW4kb-v"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"Xkm45ylGh2O4"},"source":["from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"220D8xq0ZBKX"},"source":["#from datasets import load_metric\n","#import numpy as np\n","\n","#accuracy_metric = load_metric(\"accuracy\")\n","\n","#def compute_metrics(eval_pred):\n"," #   predictions, labels = eval_pred\n","  #  predictions = np.argmax(predictions, axis=1)\n","    # metrics from the datasets library have a `compute` method\n","    #  return accuracy_metric.compute(predictions=predictions, references=labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":518},"id":"7pRmuYoNka_p","executionInfo":{"status":"error","timestamp":1613574818017,"user_tz":-60,"elapsed":3902237,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"b897963c-3ff8-43c2-dd36-61a772e5e42b"},"source":["model_dir=\"./\"\n","\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir = model_dir +  'prueba/results',          # output directory\n","    overwrite_output_dir = True,\n","    evaluation_strategy='epoch',\n","    num_train_epochs=3,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir = model_dir +  'prueba/logs',            # directory for storing logs\n","    logging_steps=10,\n","    load_best_model_at_end = True,\n","    #report_to = 'wandb',           # enable logging to W&B\n","    run_name = 'EN - DE'   # name of the W&B run\n",")\n","\n","trainer = Trainer(\n","    model = model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args = training_args,                  # training arguments, defined above\n","    train_dataset = train_data,           # training dataset\n","    eval_dataset = test_data,             # evaluation dataset\n","    compute_metrics=compute_metrics            \n",")\n","\n","trainer.train()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.19<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">EN - DE</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/lucialarraona/RATING%20CLASSIFICATION%20mBERT\" target=\"_blank\">https://wandb.ai/lucialarraona/RATING%20CLASSIFICATION%20mBERT</a><br/>\n","                Run page: <a href=\"https://wandb.ai/lucialarraona/RATING%20CLASSIFICATION%20mBERT/runs/16qqpjj1\" target=\"_blank\">https://wandb.ai/lucialarraona/RATING%20CLASSIFICATION%20mBERT/runs/16qqpjj1</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20210217_141243-16qqpjj1</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='4546' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 4546/37500 1:00:49 < 7:21:03, 1.25 it/s, Epoch 0.36/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-44c6fb98b0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"ZQqEd8amkgYo"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173},"id":"s_SB4_Fokf96","executionInfo":{"status":"ok","timestamp":1613479523725,"user_tz":-60,"elapsed":36482,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"58d363a8-2476-4381-dcb8-50ee2aa0dd8c"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:35]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 3.0,\n"," 'eval_accuracy': 0.395,\n"," 'eval_f1': 0.4023793173405573,\n"," 'eval_loss': 1.5324207544326782,\n"," 'eval_precision': 0.4795595150484503,\n"," 'eval_recall': 0.395,\n"," 'eval_runtime': 35.7113,\n"," 'eval_samples_per_second': 28.002}"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"6Z6LppM4kleF"},"source":["##Save Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rtqsAxzEkk90","executionInfo":{"status":"ok","timestamp":1613481303410,"user_tz":-60,"elapsed":810,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"212feeb5-9e38-472c-a984-db1ab2ba29a4"},"source":["!ls drive/MyDrive/TFG_1/Modelos_entrenados/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Rating_text_mBERT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HA1lcbOkqot","executionInfo":{"status":"ok","timestamp":1613481332149,"user_tz":-60,"elapsed":28838,"user":{"displayName":"lu ls","photoUrl":"","userId":"03605438839658261603"}},"outputId":"2ec7a0a4-2b60-4ab3-abb7-c941e543feca"},"source":["# saving the fine tuned model & tokenizer\n","model_path = \"drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_mBERT\"\n","trainer.save_model(model_path)\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_mBERT/tokenizer_config.json',\n"," 'drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_mBERT/special_tokens_map.json',\n"," 'drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_mBERT/vocab.txt',\n"," 'drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_mBERT/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"oIP3b3vfmofI"},"source":["# mBertForSequenceClassification - RATING\n","- ClasificaciÃ³n Rating a partir de review_body + titulo"]},{"cell_type":"code","metadata":{"id":"7eWwkqfenEXU"},"source":["RANDOM_SEED=8\n","MAX_LENGTH=512\n","\n","\n","## CLASES DEL CLASIFICADOR \n","\n","class_names = ['0','1','2','3','4'] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"72mwnY_NnVF7"},"source":["#TOKENIZAMOS LOS DATAFRAMES\n","\n","train_encodings = tokenizer(df_train.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","val_encodings = tokenizer(df_valid.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","test_encodings = tokenizer(df_test.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWF8igOLpDaC"},"source":["class GPReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEuWipzwpDq2"},"source":["train_labels = df_train.star_rating.values\n","val_labels = df_valid.star_rating.values\n","test_labels = df_test.star_rating.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQE5cOW_pED6"},"source":["train_data = GPReviewDataset(train_encodings, torch.from_numpy(train_labels))\n","val_data = GPReviewDataset(val_encodings, torch.from_numpy(val_labels))\n","test_data = GPReviewDataset(test_encodings, torch.from_numpy(test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PV_Bq6tFqlM3"},"source":["##Â Lo definimos de nuevo unicamente con el proposito de usar las secciones del documento de forma independiente \n","\n","model = BertForSequenceClassification.from_pretrained(\n","    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(class_names), # The number of output labels--2 for binary classification.  si pones num_labels=1 hace MSE LOSS\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False ,# Whether the model returns all hidden-states.   \n","    vocab_size=tokenizer.vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LaJTpnfqmZT"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uIgVakt2qWUB"},"source":["##Â Training"]},{"cell_type":"code","metadata":{"id":"E7voNFqXqEMs"},"source":["model_dir=\"./\"\n","\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir = model_dir +  'prueba/results',          # output directory\n","    overwrite_output_dir = True,\n","    evaluation_strategy='epoch',\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir = model_dir +  'prueba/logs',            # directory for storing logs\n","    logging_steps=10,\n","    #load_best_model_at_end = True\n",")\n","\n","trainer = Trainer(\n","    model = model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args = training_args,                  # training arguments, defined above\n","    train_dataset = train_data,         # training dataset\n","    eval_dataset = test_data,\n","    compute_metrics=compute_metrics       # evaluation dataset             \n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8Asx8Rmq6Lr"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"2L-JmITUq-pK"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4AU2w-_zrACw"},"source":["## Save Model"]},{"cell_type":"code","metadata":{"id":"L1saT5KIq_XM"},"source":["!ls drive/MyDrive/TFG_1/Modelos_entrenados/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3A8ZS_Dmrla_"},"source":["# saving the fine tuned model & tokenizer\n","model_path = \"drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_title_mBERT\"\n","trainer.save_model(model_path)\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UWlNtsLFm7Le"},"source":["# mBertForSequenceClassification - RATING\n","- ClasificaciÃ³n Rating a partir de review_body + titulo + categoria"]},{"cell_type":"code","metadata":{"id":"gZWkAaG_m0AA"},"source":["RANDOM_SEED=8\n","MAX_LENGTH=512\n","\n","\n","## CLASES DEL CLASIFICADOR \n","\n","class_names = ['0','1','2','3','4'] \n","#class_names = ['0','1'] \n","#class_names = ['1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Djpzu7zDr_NQ"},"source":["#TOKENIZAMOS LOS DATAFRAMES\n","\n","train_encodings = tokenizer(df_train.text_title_cat.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","val_encodings = tokenizer(df_valid.text_title_cat.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","test_encodings = tokenizer(df_test.text_title_cat.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7JCGgT6sGp_"},"source":["class GPReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4cabtvhsG61"},"source":["train_labels = df_train.star_rating.values\n","val_labels = df_valid.star_rating.values\n","test_labels = df_test.star_rating.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zePdoA_RsHUZ"},"source":["train_data = GPReviewDataset(train_encodings, torch.from_numpy(train_labels))\n","val_data = GPReviewDataset(val_encodings, torch.from_numpy(val_labels))\n","test_data = GPReviewDataset(test_encodings, torch.from_numpy(test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaGKqNmKsHdo"},"source":["model = BertForSequenceClassification.from_pretrained(\n","    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(class_names), # The number of output labels--2 for binary classification.  si pones num_labels=1 hace MSE LOSS\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False ,# Whether the model returns all hidden-states.   \n","    vocab_size=tokenizer.vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QYkVxCGCsSEe"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BjK0hyNJsWKL"},"source":["##Â Training"]},{"cell_type":"code","metadata":{"id":"r9V2p5zssWKL"},"source":["model_dir=\"./\"\n","\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir = model_dir +  'prueba/results',          # output directory\n","    overwrite_output_dir = True,\n","    evaluation_strategy='epoch',\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir = model_dir +  'prueba/logs',            # directory for storing logs\n","    logging_steps=10,\n","    #load_best_model_at_end = True\n",")\n","\n","trainer = Trainer(\n","    model = model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args = training_args,                  # training arguments, defined above\n","    train_dataset = train_data,         # training dataset\n","    eval_dataset = test_data,             # evaluation dataset\n","    compute_metrics=compute_metrics             \n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_iPPNUAtsbr8"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"w5eIetv3sbr9"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1gw9jk_6sf3g"},"source":["## Save Model"]},{"cell_type":"code","metadata":{"id":"W-BsPtyrsf3g"},"source":["!ls drive/MyDrive/TFG_1/Modelos_entrenados/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caRv1tnWsj9u"},"source":["# saving the fine tuned model & tokenizer\n","model_path = \"drive/MyDrive/TFG_1/Modelos_entrenados/Rating_text_title_cat_mBERT\"\n","trainer.save_model(model_path)\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lYZavFpEtnqi"},"source":["# BertForSequenceClassification - CATEGORÃA\n","\n","- ClasificaciÃ³n de categorias de productos a partir del review_body"]},{"cell_type":"code","metadata":{"id":"AKjb-VZytvc7"},"source":["RANDOM_SEED=8\n","MAX_LENGTH=512\n","\n","\n","## CLASES DEL CLASIFICADOR \n","\n","class_names = df_train.product_category.unique().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6capieK4vwhL"},"source":["#TOKENIZAMOS LOS DATAFRAMES\n","\n","train_encodings = tokenizer(df_train.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","val_encodings = tokenizer(df_valid.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","test_encodings = tokenizer(df_test.review_body.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-6CC3a5Bv0nh"},"source":["class GPReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"md3llmJzv3qv"},"source":["train_labels = df_train.product_category_cod.values\n","val_labels = df_valid.product_category_cod.values\n","test_labels = df_test.product_category_cod.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIj_A7OrwfPi"},"source":["train_data = GPReviewDataset(train_encodings, torch.from_numpy(train_labels))\n","val_data = GPReviewDataset(val_encodings, torch.from_numpy(val_labels))\n","test_data = GPReviewDataset(test_encodings, torch.from_numpy(test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1JK8Ir_wqJg"},"source":["model = BertForSequenceClassification.from_pretrained(\n","    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(class_names), # The number of output labels--2 for binary classification.  si pones num_labels=1 hace MSE LOSS\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False ,# Whether the model returns all hidden-states.   \n","    vocab_size=tokenizer.vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDiTBf-qwxLR"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ygQk1htBw1P-"},"source":["##Â Training"]},{"cell_type":"code","metadata":{"id":"SfGPC8FGw1P-"},"source":["model_dir=\"./\"\n","\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir = model_dir +  'prueba/results',          # output directory\n","    overwrite_output_dir = True,\n","    evaluation_strategy='epoch',\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir = model_dir +  'prueba/logs',            # directory for storing logs\n","    logging_steps=10,\n","    #load_best_model_at_end = True\n",")\n","\n","trainer = Trainer(\n","    model = model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args = training_args,                  # training arguments, defined above\n","    train_dataset = train_data,         # training dataset\n","    eval_dataset = test_data,            # evaluation dataset\n","    compute_metrics = compute_metrics             \n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M0QVxSGJw36g"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"8xtj1Aslw36g"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZfNk-hFw6tB"},"source":["## Save Model"]},{"cell_type":"code","metadata":{"id":"wYd62Bxow6tC"},"source":["!ls drive/MyDrive/TFG_1/Modelos_entrenados/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s80oYLXMw6tC"},"source":["# saving the fine tuned model & tokenizer\n","model_path = \"drive/MyDrive/TFG_1/Modelos_entrenados/Category_text_mBERT\"\n","trainer.save_model(model_path)\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wiMpXakcxleJ"},"source":["# BertForSequenceClassification - CATEGORÃA\n","\n","- ClasificaciÃ³n de categorias de productos a partir del review_body + titulo"]},{"cell_type":"code","metadata":{"id":"PPDbtxuKxleJ"},"source":["RANDOM_SEED=8\n","MAX_LENGTH=512\n","\n","\n","## CLASES DEL CLASIFICADOR \n","\n","class_names = df_train.product_category.unique().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulc-JJYcxleJ"},"source":["#TOKENIZAMOS LOS DATAFRAMES\n","\n","train_encodings = tokenizer(df_train.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","val_encodings = tokenizer(df_valid.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')\n","\n","test_encodings = tokenizer(df_test.text_title.values.tolist(), #truncation=True, padding=True,\n","      add_special_tokens=True,\n","      truncation=True,\n","      max_length=MAX_LENGTH,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UZj8ZZ4KxleK"},"source":["class GPReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5O-AjcNMxleK"},"source":["train_labels = df_train.product_category_cod.values\n","val_labels = df_valid.product_category_cod.values\n","test_labels = df_test.product_category_cod.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeV2NMDExleK"},"source":["train_data = GPReviewDataset(train_encodings, torch.from_numpy(train_labels))\n","val_data = GPReviewDataset(val_encodings, torch.from_numpy(val_labels))\n","test_data = GPReviewDataset(test_encodings, torch.from_numpy(test_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XapCe4rjxleK"},"source":["model = BertForSequenceClassification.from_pretrained(\n","    PRE_TRAINED_MODEL_NAME, # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = len(class_names), # The number of output labels--2 for binary classification.  si pones num_labels=1 hace MSE LOSS\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False ,# Whether the model returns all hidden-states.   \n","    vocab_size=tokenizer.vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfN6Pyx8xleL"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2P4MFgYmxleL"},"source":["##Â Training"]},{"cell_type":"code","metadata":{"id":"XS5_UIwSxleL"},"source":["model_dir=\"./\"\n","\n","from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir = model_dir +  'prueba/results',          # output directory\n","    overwrite_output_dir = True,\n","    evaluation_strategy='epoch',\n","    num_train_epochs=1,              # total number of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=16,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir = model_dir +  'prueba/logs',            # directory for storing logs\n","    logging_steps=10,\n","    #load_best_model_at_end = True\n",")\n","\n","trainer = Trainer(\n","    model = model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args = training_args,                  # training arguments, defined above\n","    train_dataset = train_data,         # training dataset\n","    eval_dataset = test_data,\n","    compute_metrics = compute_metrics            # evaluation dataset\n",")\n","\n","trainer.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRxJw2lZxleL"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"fKec_lvkxleM"},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4sNM26YyxleM"},"source":["## Save Model"]},{"cell_type":"code","metadata":{"id":"WDDjecK-xleM"},"source":["!ls drive/MyDrive/TFG_1/Modelos_entrenados/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JvegHs-xleN"},"source":["# saving the fine tuned model & tokenizer\n","model_path = \"drive/MyDrive/TFG_1/Modelos_entrenados/Category_text_title_mBERT\"\n","trainer.save_model(model_path)\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)"],"execution_count":null,"outputs":[]}]}